---
public: false
type: article
title: "Solomonoff's Induction — Part I: Will the Sun Rise Tomorrow?"
date: "2015-05-28T22:40:32.169Z"
description: The idea that inductive inference can be mathematically formalized is quite profound, and many generations of logicians and philosophers said it couldn't be done. Above all, if obtained, such formulation could be embedded in machines for the purpose of creating true artificial intelligence, such that can reason about the universe as humans do.

---

<div class="preface">
Throughout history, humans have understood the world through the recognition of patterns. Myths, rituals, calendars, and festivals, all have been dedicated to celebrate the existence of patterns. In fact, biblical creation stories all perpetuate the ending of chaos and the beginning of an eternal order. This tendency of man to seek patterns in structure and events, that is, to seek universal order, to obtain that everything has a cause, and to be able to infer about the unobserved based on what has been observed, is so inherently embedded in the human mind, that any decision, any behavior, any scientific theory can be seen as secretly emergent of the implicit belief that nature is uniform. Yet, this process of thought which derives the search for patterns, often known as inductive reasoning, has been a philosophical mystery for centuries. The idea that inductive inference can be mathematically formalized is quite profound, and many generations of logicians and philosophers said it couldn't be done. Above all, if obtained, such formulation could be embedded in machines for the purpose of creating true artificial intelligence, such that can reason about the universe as humans do. In the ’60s, Ray Solomonoff has founded the theory of universal inductive inference which some believe is a formal solution to the problem of induction.
</div>

While all cultures have specific myths through which they respond to fundamental questions, it is in their creation myths that the most profound answers are to be found. From Atum, who emerged out of the “sea of chaos” to establish order, through Marduk who won the fight against “the forces of chaos”, to Elohim, whose spirit was hovering over the “formless and void" earth, most creation myths celebrate the end of arbitrariness and the beginning of universal order, whether this order has emerged out of chaos or out of nothing (“Ex nihilo”). It is not by chance that the existence of universal laws was highlighted by many distinguished human civilizations. This sort of thinking, the fundamental belief that there is such order, is deeply embedded in human minds and is perhaps the most influential principle of thought in the history of mankind. Whether it was Mayan priests, who have interpreted natural disasters as signs of the dissatisfaction of gods with the acts of man, or scientists who have explained the velocity of a cannonball as a consequence of Neuton's laws, all were inferring about the unobserved on the basis of what has been observed, all have held the thought that past experience can serve as a foundation for general rules which dictate the future. In fact, this process of thought, often known as inductive reasoning, stands behinds humanity's most illuminating moments, as well as some of its darkest — Mythology, conspiracy theories, Racism, Witchcraft, Astrology, Superstitions, and arguably, most of the scientific method.

>“Inductive inference is the only process known to us by which essentially new knowledge comes into the world.” 
><div class="source">— Ronald Aylmer Fisher, The Design of Experiments (1935)</div>

Despite being fundamental, the inductive process of thought has been a philosophical mystery for centuries. At its core stands the profound question of justification — Is it logically justified to assume that past observations must maintain some relationship with the future? Is there any mathematical principle by which we choose a certain interpretation of reality over another? And if there isn't, does that means that logic is limited in its ability to capture the full magnitude of rational thinking, or that inferring the future from the past is simply not a rational act?

These were the questions that were asked by the Scottish philosopher David Hume. In his mid-18th book A Treatise of Human Nature, which is considered by many to be Hume's most important work and one of the most influential works in the history of philosophy, Hume asks to place all science and philosophy on a novel foundation: namely, an empirical investigation into human nature. Impressed by Isaac Newton's achievements in the physical sciences, Hume sought to introduce the same experimental method of reasoning into the study of human psychology, with the aim of discovering the "extent and force of human understanding”. For this purpose, Hume has distinguished between three possible ways by which knowledge can be formed, namely, (i) the relation of ideas, which refers to anything that is true by definition or that can be deduced from such definitions (ii) direct observations (iii) inductive reasoning, which is the generalization of singular observations. 
Here the famous problem of induction arises — Hume asks what exactly is the process that derives inductive reasoning, by which we draw general conclusions on the basis of particular samples. Hume argues that any generalization from experience must presuppose the so-called Uniformity Principle — i.e., that the course of nature is uniform in the sense that the future will resemble the past, and thus, inductive knowledge can only be justified if this presupposition is justified. Hume then states that because the Uniformity Principle cannot be deduced by definitions, nor is its truth is directly perceived, then it can only be justified by induction, which would result in a circular argument. Therefore, according to Hume, the principle of uniformity cannot be justified and hence no inductive conclusion can be ever justified.

>"That the sun will not rise tomorrow is no less intelligible a proposition and implies no more contradiction than the affirmation that it will rise. We should in vain, therefore, attempt to demonstrate it's falsehood."
><div class="source">— David Hume, An Enquiry Concerning Human Understanding (1748)</div>

Many have regarded Hume's argument as one of the most profound philosophical challenges imaginable since it seems to call into question the justification of one of the most fundamental ways in which we form knowledge. Naturally, many philosophers have tried to find a way around Hume’s argument — to show that science and common sense are justified in making predictions inductively. Despite these massive efforts, no response to date has received widespread acceptance. Inductive reasoning remains, as C.D. Broad’s famous apothegm, “the glory of Science” and “the scandal of Philosophy”. Some philosophers, such as Karl Popper, have instead embraced Hume’s conclusion but claimed that science is not based on inductive reasoning at all, but rather on the procedure of conjecturing hypotheses, deductively calculating their consequences, and then empirically attempting to falsify them. Others have highlighted that, although induction may never be truly justified, at least not with the kind of justification that Hume was looking for, there may be weaker, perhaps more pragmatic approaches by which inductive inference can be shown as the most useful tool, and perhaps the only tool, of knowledge formation. The most prominent of which was the German philosopher Hans Reichenbach who attempted to provide a weaker kind of justification for induction by suggesting that even if one cannot be sure that reasoning by induction would achieve successful predictions, one can still argue that if those predictions can ever be met, it would be achieved by following the principles of inductive inference, or, as stated by Brian Skyrms “the rule of induction should be adopted because one has everything to gain and nothing to lose by employing it”.

>"Induction is the glory of science and the scandal of philosophy"
><div class="source">— C. D. Broad</div>

Following the Reichenbachian spirit came other views which, instead of offering justifications for inductive inferences, in the sense of giving reasons why induction should be taken as likely to produce a true conclusion, they have rather offered reasons for following particular methods based on their optimality in achieving certain desirable epistemic ends, even if there is no guarantee that at any given stage of inquiry the results they produce are at all close to the truth. This has been highlighted in the Formal Learning Theory, which concerns the goal of reaching the truth as efficiently, or quickly, as possible, as well as the goal of minimizing the number of mind-changes, or retractions along. One significant such result is Solomonoff’s theory of universal inductive inference, which offers a general mathematical formalization for inductive inference. This, naturally, has gained great attention in relation to the possibility of general artificial intelligence, and some suggested that it is the closest possible solution for the problem of induction. Solomonoff’s theory is remarkable, not just for its mathematical elegancy in formulating some of the oldest ideas on human thought, and not just for it being a harmonious combination of these ideas, but also for what it implies about the limits of the mind. In this series of articles, I aim to describe the fundamentals of Solomonoff’s theory, along with its mathematical development and philosophical foundations.

Solomonoff’s theory is a proposition for a mathematical formalization of an inductive inference. A reasonable starting point in understanding Solomonoff’s idea is to formulate the problem of induction. This can be done rather easily. Consider an agent which exists in an unknown universe $\mu$. The agent observes some data $D=\mathrel{\mathop:}x_1,...,x_t$ that is generated by $\mu$, and has a set of hypotheses $H=\mathrel{\mathop:}h_1,h_2,...$, some of which may be good models of $\mu$. The agent's task is to decide which hypothesis in $H$ is the most likely to accurately reflect $\mu$, in a way that would allow the observing entity to predict future data. In other words, the selected hypothesis is the model of the environment that the agent uses in order to predict the future. For example, as it encountered the sequence of numbers $1,3,5,7,...$ the agent might hypothesize that $\mu$ generates the sequence of positive odd numbers, and thus, the agent can extrapolate that the next element would be $9$. Therefore, a solution to the problem of induction would be a systematic process, a methodology, an inference, which *extrapolates* on so-far-observed data to produce predictions about unobserved data. Importantly, in a successful such inference, the observer’s predictions converge towards the true value of $\mu$, in the sense that future data is predicted at an accuracy level that increases as more data is being observed. Surely, the efficiency of such a prediction process is expected to be dependent on the nature of the universe $\mu$ it exists in. If $\mu$ is, for instance, simple and periodic, we would expect a wise agent to quickly capture the essence of $\mu$, whereas, if $\mu$ is chaotic by nature, or worse, not-deterministic, then it would be understandable that even for the most intelligent agent, making good predictions is hard to impossible. Put differently, we would expect some correlation to exist between the complexity of the universe to the efficiency of predictions. To conclude, a formulation of inductive inference would be some mathematical procedure that operates on perceived data to extrapolate future data, in a way that efficiently converges towards the truth with respect to the complexity of the universe it exists in.

An implicit distinction from the above definition of the problem is that the agent *can never be certain* about the true value of $\mu$, because the number of observations is potentially endless, and, theoretically, there can always be a new observation that does not follow the currently selected hypothesis. Hence, the best that the agent can do is to use the notion of likelihood, or *plausibility*, that is, to hold the idea that a certain hypothesis is the most likely of being the true value of $\mu$. The mathematical theory that deals with assigning order relation to statements or events in respect to their plausibility in the presence of uncertainty is the *theory of probability*, and as such, it serves as the *language* of Solomonoff’s theory. In particular, given an hypothesis, the plausibility that the hypothesis describes the true $\mu$ is expressed as probability measure. Given such probability distribution over all possible hypothesis, the agent can choose to follow, i.e. to make predictions by, the most plausible hypothesis. Therefore, an important step in formalizing an inductive inference is to define a probability distribution over all possible hypothesis. 

Yet, the use of probabilities as a way to express the agent’s view about the plausibility of hypothesis in not usual. In fact, this is by any mean not how most philosophers and mathematicians have usually viewed the concept of probability throughout most of the history. The idea that probability can express one’s personal opinion imply that probability is a subjective measure, in the sense that it is not an inherent feature of reality but rather a feature of the agent’s personal mental state, namely the observer's degree of belief that a given event will occur or that a given hypothesis is true. This kind of conception, known as the subjective interpretation of probability, results in significant epistemic implications. In particular, Bayes rule, which, in objective interpretations of probability is merely a rule for obtaining conditional probabilities, receives a great epistemic importance — as probabilities represents degrees of belief, Bayes rule is the mechanism by which beliefs evolve. This approach of reasoning, known as Bayesianism, by which beliefs are tightly associated with probabilities and evolve through the use of Bayes rule, unifies the recognition of Blaise Pascal (1623 - 1662), by which uncertainty is best expressed probabilistically and that values of unknown quantities are best estimated using the principle of mathematical expectation.




